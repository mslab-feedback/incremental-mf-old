{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# 1. 跑過所有 rating\n",
    "# 2. 比較每個 rating 跟 dot 的差距\n",
    "# 3. backprobagation\n",
    "# 4. 算 loss\n",
    "# 5. converge 時結束（用 loss 判斷）\n",
    "def matrix_factorization(R,P,I,epochs,alpha,lda):\n",
    "    \n",
    "    while(epochs>0):        \n",
    "        epochs -= 1\n",
    "        # gradient descent\n",
    "        for i in tqdm(range(len(R))):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                eij = np.dot(P[i],I[j].T)-R[i][j]\n",
    "                for k in range(len(P[i])):\n",
    "                    P[i][k] = P[i][k] - alpha*(2*I[j][k]*eij-lda*P[i][k])\n",
    "                    I[j][k] = I[j][k] - alpha*(2*P[i][k]*eij-lda*I[j][k])\n",
    "\n",
    "        if epochs%2 ==0:\n",
    "            # loss calculation\n",
    "            e_all = 0\n",
    "            r_num = 0\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    if R[i][j]==0:\n",
    "                        continue\n",
    "                    r_num += 1\n",
    "                    e_all += ((np.dot(P[i],I[j].T)).astype(int)-R[i][j])**2\n",
    "            rmse = e_all/r_num\n",
    "            print(\"epoch:\",epochs,\", rmse:\",rmse)\n",
    "            print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "data_dir = '../data'\n",
    "file_folder = 'movielens'\n",
    "file_name   = 'movielens_offline_train.csv'\n",
    "file_path = os.path.join(data_dir,file_folder,file_name)\n",
    "\n",
    "file_test_name   = 'movielens_offline_test.csv'\n",
    "file_test_path = os.path.join(data_dir,file_folder,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(file_path, header=None)\n",
    "df_test = pd.read_csv(file_test_path, header=None)\n",
    "df_train = df_train.loc[:,[0,1]]\n",
    "df_test  = df_test.loc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 9701\n"
     ]
    }
   ],
   "source": [
    "unique_users = df_train[0].unique()\n",
    "unique_items = df_train[1].unique()\n",
    "N = len(unique_users)\n",
    "M = len(unique_items)\n",
    "print(N,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_user_id = list(unique_users)\n",
    "index_to_item_id = list(unique_items)\n",
    "item_id_to_index = {}\n",
    "user_id_to_index = {}\n",
    "for _index, u_id in enumerate(unique_users):\n",
    "    user_id_to_index[u_id] = _index\n",
    "for _index, i_id in enumerate(unique_items):\n",
    "    item_id_to_index[i_id] = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPLICIT = True\n",
    "\n",
    "R = np.zeros([N,M])\n",
    "for r in data:\n",
    "    u_id = r[0]\n",
    "    i_id = r[1]\n",
    "    if IMPLICIT:\n",
    "        R[user_id_to_index[u_id]][item_id_to_index[i_id]] = 1\n",
    "    else:\n",
    "        R[user_id_to_index[u_id]][item_id_to_index[i_id]] = r[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "N = len(unique_users)\n",
    "M = len(unique_items)\n",
    "dim = 10\n",
    "P = np.random.rand(N,dim)\n",
    "I = np.random.rand(M,dim)\n",
    "alpha = 0.0005\n",
    "lda   = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [00:08<00:00, 84.64it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 72.13it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 68.72it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 84.46it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 69.57it/s]\n",
      "100%|██████████| 610/610 [00:09<00:00, 67.06it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 84.08it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 70.87it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 83.86it/s]\n",
      "100%|██████████| 610/610 [00:08<00:00, 70.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8d5e75ba08e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix_factorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-54599ee08add>\u001b[0m in \u001b[0;36mmatrix_factorization\u001b[0;34m(R, P, I, epochs, alpha, lda)\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mr_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0me_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_all\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mr_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\", rmse:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matrix_factorization(R,P,I,epochs,alpha,lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100226\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i, r in df_t.iterrows():\n",
    "    i+=1\n",
    "    u_id = str(int(r[0]))\n",
    "    i_id = str(int(r[1]))\n",
    "    print(u_id,i_id)\n",
    "    n = u2r[u_id]\n",
    "    m = i2r[i_id]\n",
    "    print(n,m)\n",
    "    print(\"R_:\",R[n][m])\n",
    "    print(\"R':\",np.dot(P[n],I.T))\n",
    "    print('-----------------')\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_id = str(int(df_t[0][0]))\n",
    "n = u2r[u_id]\n",
    "rating_list = np.dot(P[n],I.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84221006, 5.50993275, 5.48095541, ..., 1.59849014, 1.58650548,\n",
       "       1.45987863])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(rating_list)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightfm.datasets import fetch_stackexchange\n",
    "\n",
    "data_dir = '../data'\n",
    "file_folder = 'movielens'\n",
    "file_name   = 'movielens_offline_train.csv'\n",
    "file_path = os.path.join(data_dir,file_folder,file_name)\n",
    "\n",
    "file_test_name   = 'movielens_offline_test.csv'\n",
    "file_test_path = os.path.join(data_dir,file_folder,file_name)\n",
    "\n",
    "data = fetch_stackexchange('crossvalidated',\n",
    "                           test_set_fraction=0.1,\n",
    "                           indicator_features=False,\n",
    "                           tag_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(file_path, header=None)\n",
    "test = pd.read_csv(file_test_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[:,[0,1]]\n",
    "test  = test.loc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3221x72360 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 57830 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3221, 72360)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "model.fit(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-03d5ce5e953b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightFM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_at_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.data.Dataset import build_interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'helpers' has no attribute 'df_to_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d088e030fdc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'helpers' has no attribute 'df_to_matrix'"
     ]
    }
   ],
   "source": [
    "helpers.df_to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
